<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<title>Rem ‚Äî Companion</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<script type="importmap">
{
  "imports": {
    "three": "/static/vendor/three.module.js"
  }
}
</script>
<style>
  :root{ --fg:#f4f7ff; --glass:#0b1020cc; --line:#23314a; --green:#00d68f; }
  *{box-sizing:border-box;font-family:Inter,system-ui,Segoe UI,Roboto,sans-serif}
  html,body{height:100%;margin:0;background:#0b0e14;color:var(--fg);overflow:hidden}
  #scene3d{position:fixed;inset:0;z-index:0;background:#0c0f18}
  #panel{position:fixed;right:0;top:0;height:100%;width:min(520px,90vw);
         display:flex;flex-direction:column;gap:12px;padding:18px;
         background:linear-gradient(180deg,#0b1020a0,#0b1020a0);backdrop-filter:blur(8px);
    border-left:1px solid #1e2a3f;z-index:2;
    transform:translateX(100%); transition:transform .25s ease}
  #panel.open{ transform:translateX(0) }
  #log{flex:1;min-height:0;overflow:auto;padding-right:6px}
  .bubble{padding:12px 14px;border-radius:14px;margin:8px 0;border:1px solid #1e2a3f}
  .user{background:#12233e}.bot{background:#151c2a}
  .row{display:flex;gap:8px}
  input,button{font:15px/1.2 inherit;padding:12px 14px;border-radius:14px;border:1px solid #1e2a3f;background:#101827;color:var(--fg)}
  input{flex:1;min-width:0} button{cursor:pointer;font-weight:600}
  button:hover{filter:brightness(1.06)} button:disabled{opacity:.55;cursor:not-allowed}
  #voicebar{position:fixed;left:16px;bottom:16px;z-index:2;display:flex;align-items:center;gap:10px;
            background:var(--glass);border:1px solid #1e2a3f;padding:8px 12px;border-radius:12px}
  .pill{display:inline-flex;align-items:center;gap:8px;padding:6px 10px;border-radius:999px;background:#0e1627;border:1px solid #26344b;font-size:13px}
  .dot{width:10px;height:10px;border-radius:50%;background:#78859a}.dot.on{background:var(--green);box-shadow:0 0 10px var(--green)}
  #badge{position:fixed;top:16px;left:16px;z-index:2;padding:8px 12px;border-radius:12px;border:1px solid #1e2a3f;background:var(--glass);font-weight:700;letter-spacing:.3px}
  #hambtn{position:fixed;top:16px;right:16px;z-index:3;padding:8px 10px;border-radius:10px;border:1px solid #1e2a3f;background:var(--glass);font-weight:700}
  #subtitle{position:fixed;left:50%;bottom:18%;transform:translateX(-50%);z-index:2;
       max-width:min(70vw,900px); text-align:center; padding:10px 14px; border-radius:12px;
       background:#0e1627cc; border:1px solid #23314a; color:#e9f2ff; opacity:0; transition:opacity .25s ease}
  #subtitle.show{ opacity:1 }
  #disclaimer{position:fixed;left:50%;top:12px;transform:translateX(-50%);z-index:3;
    padding:8px 12px;border-radius:10px;border:1px solid #2a3a55;background:#0b1020e6;color:#b9c6db;
    font-size:12.5px}
</style>
</head>
<body>
  <div id="scene3d"><div style="position:absolute;inset:0;display:grid;place-items:center;color:#9fb3d1">Loading 3D‚Ä¶</div></div>
  <div id="badge">Rem</div>
  <button id="hambtn">‚ò∞</button>
  <div id="subtitle" aria-live="polite"></div>
  <div id="disclaimer">Preview build: This experience is under active development and may be imperfect.</div>

  <aside id="panel">
    <div style="font-weight:700;letter-spacing:.4px">Chat</div>
    <div id="log"></div>
    <div class="row">
      <input id="inp" placeholder="Say something‚Ä¶" />
      <button id="send">Send</button>
    </div>
  </aside>

  <div id="voicebar">
    <button id="mic">üéôÔ∏è Start Voice</button>
    <button id="stop" disabled>‚èπÔ∏è Stop</button>
  <button id="test">‚ñ∂Ô∏è Test Voice</button>
    <span class="pill"><span id="micdot" class="dot"></span><span id="miclabel">Idle</span></span>
  </div>

<script type="module">
/* ====== Put your Ready Player Me GLB URL here (with ARKit morphs) ====== */
const RPM_AVATAR_URL =
  "/static/models/blessedboy.glb";

/* ====== Imports (use import map to resolve 'three') ====== */
import * as THREE from "three";
import { GLTFLoader }  from "/static/vendor/GLTFLoader.js";
import { DRACOLoader } from "/static/vendor/DRACOLoader.js";
import { OrbitControls } from "/static/vendor/OrbitControls.js";

/* ====== UI refs ====== */
const scene3d   = document.getElementById('scene3d');
const logEl     = document.getElementById('log');
const inp       = document.getElementById('inp');
const sendBtn   = document.getElementById('send');
const micBtn    = document.getElementById('mic');
const stopBtn   = document.getElementById('stop');
const testBtn   = document.getElementById('test');
const micdot    = document.getElementById('micdot');
const miclabel  = document.getElementById('miclabel');
const panelEl   = document.getElementById('panel');
const hambtn    = document.getElementById('hambtn');
const subtitle  = document.getElementById('subtitle');

/* ====== log ====== */
function add(text, who){
  const d = document.createElement('div');
  d.className = 'bubble '+who;
  d.textContent = text;
  logEl.appendChild(d); d.scrollIntoView({behavior:'smooth', block:'end'});
}

/* ====== 3D avatar (deferred) ====== */
let renderer, scene, camera, controls, clock;
let jawTargets=[], smileTargets=[], blinkLeftTargets=[], blinkRightTargets=[], blinkBothTargets=[], headBone=null, jawBone=null, root=null;
let jawEnergy=0, threeReady=false;
let smile=0, blink=0, nextBlinkT=0, lastT=0, prevSmileLevel=0;
let entrance = { active: true, startT: 0, fromZ: 0, toZ: 0 };

function setJawEnergy(level){ jawEnergy = Math.max(0, Math.min(1, level)); }
function setSmile(level){ smile = Math.max(0, Math.min(1, level)); }
function setBlink(level){ blink = Math.max(0, Math.min(1, level)); }

function frameObject(obj){
  const box = new THREE.Box3().setFromObject(obj);
  const size = new THREE.Vector3(), center = new THREE.Vector3();
  box.getSize(size); box.getCenter(center);
  center.y += size.y*0.28;                                        // bias toward face/upper body
  const dist = (size.y*0.55) / Math.tan(THREE.MathUtils.degToRad(camera.fov*0.5));
  camera.position.set(center.x, center.y + 0.06, center.z + dist*0.48);  // zoom in closer
  camera.lookAt(center);
  controls.target.copy(center); controls.update();
}
function faceCameraIfBackwards(){
  if(!headBone || !root) return;
  const fwd = new THREE.Vector3(0,0,1);
  headBone.getWorldDirection(fwd);
  const toCam = new THREE.Vector3().subVectors(camera.position, headBone.getWorldPosition(new THREE.Vector3())).normalize();
  if (fwd.dot(toCam) < 0) root.rotateY(Math.PI);
}

async function init3D(url){
  const w = scene3d.clientWidth, h = scene3d.clientHeight;
  renderer = new THREE.WebGLRenderer({ antialias:true, alpha:true, powerPreference:'high-performance' });
  renderer.setPixelRatio(Math.min(2, window.devicePixelRatio||1));
  renderer.setSize(w, h);
  try{
    renderer.outputColorSpace = THREE.SRGBColorSpace;
    renderer.toneMapping = THREE.ACESFilmicToneMapping;
    renderer.toneMappingExposure = 1.1;
    renderer.physicallyCorrectLights = true;
  }catch{}
  scene3d.innerHTML=''; scene3d.appendChild(renderer.domElement);

  scene = new THREE.Scene();
  camera = new THREE.PerspectiveCamera(24, w/h, 0.1, 100);

  const hemi = new THREE.HemisphereLight(0xffffff, 0x334466, 0.9);
  const dir  = new THREE.DirectionalLight(0xffffff, 1.0); dir.position.set(1,1,1);
  scene.add(hemi, dir);

  controls = new OrbitControls(camera, renderer.domElement);
  controls.enableZoom = false; controls.enablePan = false;

  clock = new THREE.Clock();
  const loader = new GLTFLoader();
  const draco  = new DRACOLoader();
  draco.setDecoderPath("/static/vendor/draco/");
  loader.setDRACOLoader(draco);

  const gltf = await loader.loadAsync(url);
  root = gltf.scene; scene.add(root);

  // Increase texture filtering quality
  try{
    const aniso = renderer.capabilities.getMaxAnisotropy?.() || 8;
    root.traverse(o=>{
      const m = o.material; if(!m) return;
      const tx = ['map','normalMap','metalnessMap','roughnessMap','emissiveMap','aoMap'];
      for(const k of tx){ if(m[k]) m[k].anisotropy = aniso; }
    });
  }catch{}

  root.traverse(o=>{
    if (/head/i.test(o.name) && !headBone) headBone = o;
  if (!jawBone && /jaw|mouth/i.test(o.name)) jawBone = o; // fallback bone-based jaw
    if (o.isMesh && o.morphTargetDictionary && o.morphTargetInfluences){
      const dict = o.morphTargetDictionary;
      for (const key in dict){
        const idx = dict[key]; const k = key.toLowerCase();
        if (k.includes('jawopen') || k.includes('mouthopen') || k.includes('aa') || k.includes('ah')) {
          jawTargets.push({ mesh:o, idx });
        }
        if (k.includes('smile') || k.includes('happy') || k.includes('smirk')) { smileTargets.push({ mesh:o, idx }); }
        const isBlink = k.includes('blink') || (k.includes('eye') && (k.includes('close') || k.includes('shut')));
        if (isBlink) {
          const isLeft = k.includes('left') || k.includes('l ') || k.endsWith('_l') || k.endsWith('.l') || k.includes('eye_l');
          const isRight = k.includes('right') || k.includes('r ') || k.endsWith('_r') || k.endsWith('.r') || k.includes('eye_r');
          if (isLeft) blinkLeftTargets.push({ mesh:o, idx });
          else if (isRight) blinkRightTargets.push({ mesh:o, idx });
          else blinkBothTargets.push({ mesh:o, idx });
        }
      }
    }
  });

  frameObject(root);
  faceCameraIfBackwards();

  // Entrance: start slightly forward and move toward camera
  entrance.startT = clock.getElapsedTime();
  entrance.fromZ = (root.position.z || 0) + 0.9;
  entrance.toZ = root.position.z || 0;
  root.position.z = entrance.fromZ;

  function loop(){
  const t = clock.getElapsedTime();
    // More visible idle motion
    const yaw = Math.sin(t*0.5) * 0.08;   // ~¬±4.5¬∞
    const bob = Math.sin(t*0.9) * 0.035;  // ~3.5 cm
    if (root){
      // Entrance easing (quad out)
      if (entrance.active){
        const dt = t - entrance.startT;
        const dur = 2.2; const p = Math.min(1, dt/dur); const e = 1 - (1-p)*(1-p);
        root.position.z = entrance.fromZ + (entrance.toZ - entrance.fromZ)*e;
        if (p >= 1) entrance.active = false;
      }
      root.rotation.y = yaw;
      root.position.y = bob * (entrance.active ? 1.8 : 1.0);
    }

    // Head motion: slight idle nod + speech-driven component
    const idleNod = Math.sin(t*0.8) * 0.03;     // ~¬±1.7¬∞
    const speakNod = (jawEnergy-0.15) * 0.04;   // add a bit more when talking
    if (headBone) headBone.rotation.x = THREE.MathUtils.lerp(headBone.rotation.x, idleNod + speakNod, 0.15);

  // Apply mouth openness to detected morph targets (or rotate jaw bone if no morphs)
    if (jawTargets.length){
      for (const j of jawTargets){ j.mesh.morphTargetInfluences[j.idx] = jawEnergy; }
    } else if (jawBone) {
      const maxOpen = THREE.MathUtils.degToRad(12); // ~12¬∞
      jawBone.rotation.x = THREE.MathUtils.lerp(jawBone.rotation.x, jawEnergy * maxOpen, 0.2);
    }

  // Smile: subtle when idle, stronger while speaking
  const idleSmile = 0.08 + Math.max(0, Math.sin(t*0.6))*0.04;
  const speakSmile = jawEnergy * 0.25;
  const sLevel = THREE.MathUtils.clamp(idleSmile + speakSmile, 0, 0.5);
  for (const s of smileTargets){ s.mesh.morphTargetInfluences[s.idx] = THREE.MathUtils.lerp(s.mesh.morphTargetInfluences[s.idx]||0, sLevel, 0.1); }

  // Natural blinking
  if (t > nextBlinkT){ nextBlinkT = t + 3 + Math.random()*3; lastT = t; }
  const blinkPhase = Math.max(0, 1 - Math.abs((t-lastT) - 0.15)/0.15); // quick close/open ~0.3s
  const bLevel = THREE.MathUtils.clamp(blinkPhase, 0, 1);
  for (const b of blinkLeftTargets){ b.mesh.morphTargetInfluences[b.idx] = bLevel; }
  for (const b of blinkRightTargets){ b.mesh.morphTargetInfluences[b.idx] = bLevel; }
  for (const b of blinkBothTargets){ b.mesh.morphTargetInfluences[b.idx] = bLevel; }

    // Smile indicator
    if (sLevel > 0.33 && prevSmileLevel <= 0.33) { showSubtitle('[smiles]', 1200); }
    prevSmileLevel = sLevel;

    controls.update();
    renderer.render(scene, camera);
    requestAnimationFrame(loop);
  }
  loop();

  window.addEventListener('resize', ()=>{
    const W = scene3d.clientWidth, H = scene3d.clientHeight;
    renderer.setSize(W,H); camera.aspect = W/H; camera.updateProjectionMatrix();
    if (root) frameObject(root);
  });

  threeReady = true;
}
function schedule3D(){
  const start = ()=>
    init3D(RPM_AVATAR_URL)
      .catch(async (err)=>{
        console.warn("Remote 3D load failed, trying local fallback:", err);
        try{
          await init3D('/static/models/blessedboy.glb');
        }catch(e2){
          console.error("Local 3D fallback failed:", e2);
          const overlay = scene3d.querySelector('div');
          if(overlay) overlay.textContent = '3D failed to load. Check network or local assets.';
        }
      })
      .finally(()=>scene3d.style.pointerEvents = "auto");
  (window.requestIdleCallback || ((f)=>setTimeout(f,250)))(start);
}
scene3d.style.pointerEvents = "none";
// Basic WebGL support check
try{
  const test = document.createElement('canvas').getContext('webgl') || document.createElement('canvas').getContext('experimental-webgl');
  if(!test){
    const overlay = scene3d.querySelector('div');
    if(overlay) overlay.textContent = 'WebGL not supported. Try a newer browser or update graphics drivers.';
  }else{
    schedule3D();
    // If it takes too long, surface a hint
    setTimeout(()=>{
      if(!threeReady){
        const overlay = scene3d.querySelector('div');
        if(overlay) overlay.textContent = 'Still loading 3D‚Ä¶ Check /static/vendor and /static/models files.';
      }
    }, 8000);
  }
}catch{
  const overlay = scene3d.querySelector('div');
  if(overlay) overlay.textContent = '3D init error. See console for details.';
}

/* ====== TTS with visemes ====== */
let curTtsCtrl = null; // abort controller for active TTS fetch
async function ttsFull(text){
  // Retry a couple times on 429/5xx to smooth out transient throttling
  let lastErr;
  for(let attempt=0; attempt<3; attempt++){
    try{
      const ctrl = new AbortController(); curTtsCtrl = ctrl;
      const r = await fetch('/api/tts',{
        method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({text}), signal: ctrl.signal
      });
      if(r.status===429 || r.status===503 || r.status===502){
        const back = 250*Math.pow(2,attempt) + Math.random()*150; await new Promise(res=>setTimeout(res, back));
        continue;
      }
      const d = await r.json(); return d; // {audio_b64, marks}
    }catch(e){
      if(e && (e.name==='AbortError' || String(e).includes('AbortError'))){ throw e; }
      lastErr = e; const back = 200*Math.pow(2,attempt); await new Promise(res=>setTimeout(res, back));
    } finally {
      curTtsCtrl = null;
    }
  }
  throw lastErr || new Error('tts-retries-exhausted');
}

/* ====== Lip-sync (visemes + RMS fallback) ====== */
let speaking=false, currentAudio=null, audioCtx=null, raf=null;
let curStreamCtrl = null; // abort controller for active chat_stream
function stopSpeaking(){
  speaking=false;
  try{ if(currentAudio){ currentAudio.pause(); currentAudio.src=''; } }catch{}
  if(raf) cancelAnimationFrame(raf); currentAudio=null;
  setJawEnergy(0);
  if(audioCtx){ try{ audioCtx.close(); }catch{} audioCtx=null; }
  try{ if(window.speechSynthesis){ window.speechSynthesis.cancel(); } }catch{}
  // Flush any queued utterances so a new prompt starts fresh
  try{ speakQ = Promise.resolve(); }catch{}
  // Abort any active streaming request so it doesn't enqueue more sentences
  try{ if(curStreamCtrl){ curStreamCtrl.abort(); curStreamCtrl = null; } }catch{}
  // Abort any active TTS fetch
  try{ if(curTtsCtrl){ curTtsCtrl.abort(); curTtsCtrl = null; } }catch{}
}
const VMAP = { "sil":0.00, "p":0.15, "t":0.2, "f":0.22, "k":0.22, "S":0.2, "T":0.22, "r":0.28, "w":0.3,
               "e":0.55, "i":0.6, "o":0.75, "u":0.78, "@":0.5, "a":0.95 };
function visemeToOpen(v){ return (VMAP[v] ?? 0.35); }

async function playAudioWithVisemes(b64, marks){
  return new Promise(async (resolve, reject)=>{
    stopSpeaking(); speaking=true;
    const audio = new Audio('data:audio/mp3;base64,'+b64); currentAudio=audio;

    let cleaned=false;
    const cleanup=(endOk=true)=>{
      if(cleaned) return; cleaned=true;
      try{ if(raf) cancelAnimationFrame(raf); }catch{}
      setJawEnergy(0);
      try{ audio.pause(); audio.src=''; }catch{}
      try{ if(audioCtx){ audioCtx.close(); } }catch{}
      audioCtx = null; currentAudio = null; speaking = false;
      endOk ? resolve() : reject(new Error('audio-playback-failed'));
    };

    try{
      audioCtx = new (window.AudioContext||window.webkitAudioContext)();
      const src = audioCtx.createMediaElementSource(audio);
      const an  = audioCtx.createAnalyser(); an.fftSize=512;
      src.connect(an); an.connect(audioCtx.destination);

      try{ if(audioCtx.state!=='running') await audioCtx.resume(); }catch{}
      let started=false;
      audio.onplay = ()=>{ started=true; };
      audio.onerror = ()=> cleanup(false);
      const startWatch = setTimeout(()=>{ if(!started) cleanup(false); }, 2500);
  audio.onended = ()=>{ clearTimeout(startWatch); cleanup(true); };
  // If we interrupt (stopSpeaking pauses audio), treat as a clean end so the queue continues
  audio.onpause = ()=>{ clearTimeout(startWatch); cleanup(true); };
      audio.play().catch(()=> cleanup(false));

      let idx=0, target=0.2, level=0.15;
      const startAt = audioCtx.currentTime;
      const data = new Uint8Array(an.frequencyBinCount);

      const tick=()=>{
        if(!speaking || cleaned) return;
        const tms = (audioCtx.currentTime - startAt)*1000;

        while(Array.isArray(marks) && idx<marks.length && marks[idx].time <= tms + 30){
          target = visemeToOpen(marks[idx].value); idx++;
        }

        an.getByteTimeDomainData(data);
        let s=0; for(let i=0;i<data.length;i++){ const v=(data[i]-128)/128; s+=v*v; }
        const rms=Math.sqrt(s/data.length);
        const assist = Math.min(0.25, rms*0.6);

        level = level*0.6 + (target+assist)*0.4;
        setJawEnergy(Math.max(0, Math.min(1, level)));

        raf = requestAnimationFrame(tick);
      };
      raf = requestAnimationFrame(tick);
    }catch(e){ cleanup(false); }
  });
}

let speakQ = Promise.resolve();
let talkGen = 0; // generation id for active talk stream
function speakWithBrowser(sentence){
  return new Promise((resolve)=>{
    try{
      stopSpeaking(); speaking=true;
      const synth = window.speechSynthesis; if(!synth){ speaking=false; return resolve(); }
      const u = new SpeechSynthesisUtterance(sentence);
      // Prefer female English voice if available
      const voices = synth.getVoices();
      const pick = voices.find(v=>/en-/i.test(v.lang) && /female|woman|salli|joanna|amy|emma|linda|rem/i.test((v.name+v.voiceURI).toLowerCase()))
                || voices.find(v=>/en-/i.test(v.lang))
                || voices[0];
      if(pick) u.voice = pick;
      u.rate = 1.0; u.pitch = 1.05; u.volume = 1.0;
      let rafId; const t0 = performance.now();
      const pump = ()=>{
        if(!speaking) return;
        const t = (performance.now()-t0)/1000;
        const v = 0.18 + 0.18*Math.abs(Math.sin(t*8.0)) + 0.06*Math.abs(Math.sin(t*13.0));
        setJawEnergy(v);
        rafId = requestAnimationFrame(pump);
      };
      u.onstart = ()=>{ pump(); };
      const cleanup = ()=>{ if(rafId) cancelAnimationFrame(rafId); setJawEnergy(0); speaking=false; resolve(); };
      u.onend = cleanup; u.onerror = cleanup; u.onpause = cleanup; u.onresume = ()=>{};
      synth.speak(u);
    }catch{ speaking=false; resolve(); }
  });
}

function enqueueSpeak(sentence){
  const s = (sentence||'').trim(); if(!s) return;
  speakQ = speakQ.then(async ()=>{
    try{
      const {audio_b64, marks} = await ttsFull(s);
      if(!audio_b64){ throw new Error('no-audio'); }
      await playAudioWithVisemes(audio_b64, marks || []);
    }catch(e){
      if(e && (e.name==='AbortError' || String(e).includes('AbortError'))){ return; }
      console.warn('Server TTS failed, using browser speech', e);
      await speakWithBrowser(s);
    }
  });
}

/* ====== Subtitles + panel toggle ====== */
let subTimer; function showSubtitle(text, ttl=4000){
  subtitle.textContent = text; subtitle.classList.add('show');
  if(subTimer) clearTimeout(subTimer);
  subTimer = setTimeout(()=>subtitle.classList.remove('show'), ttl);
}
hambtn.onclick = ()=>{ panelEl.classList.toggle('open'); };
panelEl.addEventListener('mouseleave', ()=> panelEl.classList.remove('open'));

/* ====== Streaming chat (with sentence-level TTS) ====== */
async function talk(text){
  const myGen = ++talkGen;
  stopSpeaking();
  const q = (text||'').trim(); if(!q) return;
  add(q,'user');

  const bubble = document.createElement('div'); bubble.className='bubble bot'; bubble.textContent=''; logEl.appendChild(bubble);

  let buf=''; const dec=new TextDecoder();
  try{
    // Create a fresh controller for this stream and store it globally for interruption
    const ctrl = new AbortController(); curStreamCtrl = ctrl;
    const r = await fetch('/api/chat_stream', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({text:q, session_id:'local-1'}), signal: ctrl.signal});
    if(!r.ok){ throw new Error('stream-status-'+r.status); }
    const reader = r.body.getReader(); let leftover='';
    while(true){
      const {value, done} = await reader.read();
      if(done){ break; }
      if(myGen !== talkGen){ break; }
      leftover += dec.decode(value, {stream:true});
      const lines = leftover.split('\n'); leftover = lines.pop();
      for(const line of lines){
        if(!line.trim()) continue;
        const {delta='', error} = JSON.parse(line);
        if(error){
          bubble.textContent += ` [${error}]`;
          if(/Chat busy|Bedrock error|Stream failure/i.test(error)){
            throw new Error('fallback-chat');
          }
          continue;
        }
  bubble.textContent += delta; buf += delta; showSubtitle(bubble.textContent.slice(-220));

        const m = buf.match(/(.+?[.!?][)"']?\s)/);
        if(m && m[1].trim().length>3){ enqueueSpeak(m[1]); buf = buf.slice(m[1].length); }
      }
    }
    if(myGen !== talkGen){ curStreamCtrl = null; return; }
  if(buf.trim()) { showSubtitle(buf.trim()); enqueueSpeak(buf.trim()); buf=''; }
    await speakQ;
    curStreamCtrl = null;
  }catch(e){
    console.error(e);
    if(e && (e.name==='AbortError' || String(e).includes('AbortError'))){
      // Interrupted: do not fallback or enqueue; just stop cleanly
      curStreamCtrl = null;
      return;
    }
    // Small backoff then fallback to non-streaming
    await new Promise(res=>setTimeout(res, 250));
    const rr = await fetch('/api/chat', {method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({text:q, session_id:'local-1'})});
    const dd = await rr.json(); bubble.textContent = dd.reply || "I'm here.";
    showSubtitle(bubble.textContent); enqueueSpeak(bubble.textContent); await speakQ;
    curStreamCtrl = null;
  }
}

/* ====== inputs & mic ====== */
sendBtn.onclick = ()=>{ const t = inp.value.trim(); if(t){ talk(t); inp.value=''; } };
inp.addEventListener('keydown', e=>{ if(e.key==='Enter'){ e.preventDefault(); sendBtn.click(); } });

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
let recog, localCtx;
let listening = false; // track mic listening state
function beep(freq=880, ms=120){
  try{
    localCtx = localCtx || new (window.AudioContext||window.webkitAudioContext)();
    const o=localCtx.createOscillator(), g=localCtx.createGain();
    o.type='sine'; o.frequency.value=freq; o.connect(g); g.connect(localCtx.destination);
    g.gain.setValueAtTime(0.0001, localCtx.currentTime);
    g.gain.exponentialRampToValueAtTime(0.25, localCtx.currentTime+0.02);
    g.gain.exponentialRampToValueAtTime(0.0001, localCtx.currentTime+ms/1000);
    o.start(); o.stop(localCtx.currentTime+ms/1000);
  }catch{}
}
function setListening(on){
  listening = !!on;
  micdot.classList.toggle('on', on);
  miclabel.textContent = on ? 'Listening‚Ä¶' : 'Idle';
  if(on && speaking) stopSpeaking();
}
micBtn.onclick = ()=>{
  if(!SpeechRecognition){ alert("Use Chrome/Edge for live speech. I can add Whisper fallback next."); return; }
  recog = new SpeechRecognition(); recog.lang='en-US'; recog.interimResults=true; recog.continuous=true;
  let buffer='';
  recog.onstart = ()=>{ micBtn.disabled=true; stopBtn.disabled=false; setListening(true); beep(820,120); };
  recog.onresult = (ev)=>{
    for(let i=ev.resultIndex;i<ev.results.length;i++){ const r=ev.results[i]; if(r.isFinal) buffer += ' '+r[0].transcript; }
    const cleaned = buffer.trim(); if(cleaned){ talk(cleaned); buffer=''; }
  };
  recog.onend = ()=>{ micBtn.disabled=false; stopBtn.disabled=true; setListening(false); beep(480,120); };
  recog.onerror = e=> console.warn(e);
  recog.start();
};
stopBtn.onclick = ()=>{
  // If mic is listening, stop mic only; otherwise stop active voice/stream if any
  try{ if(listening && recog){ recog.stop(); return; } }catch{}
  if(speaking || curStreamCtrl || curTtsCtrl){ stopSpeaking(); }
};
// Quick test to verify TTS + lip-sync without typing
testBtn.onclick = ()=>{ enqueueSpeak("Hi, I'm Rem. Nice to meet you."); };

// Try to unlock/resume audio on any user gesture, to avoid autoplay gating after interruptions
['pointerdown','keydown'].forEach(evt=>{
  window.addEventListener(evt, ()=>{
    try{ if(audioCtx && audioCtx.state!=='running'){ audioCtx.resume(); } }catch{}
    try{ if(window.speechSynthesis && window.speechSynthesis.paused){ window.speechSynthesis.resume?.(); } }catch{}
  }, {passive:true});
});
</script>
</body>
</html>
